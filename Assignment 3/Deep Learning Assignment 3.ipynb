{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xNEJ6JyC6nX"
      },
      "source": [
        "\n",
        "# Implementação e Avaliação do FixMatch com CIFAR-10\n",
        "\n",
        "### Objetivo\n",
        "Neste assignment, vocês implementarão o método FixMatch, uma técnica de aprendizado semi-supervisionado que combina aprendizado supervisionado e não supervisionado. O objetivo é aplicar o FixMatch ao dataset CIFAR-10 para treinar uma rede neural e avaliar os resultados obtidos com diferentes proporções de dados rotulados.\n",
        "\n",
        "### 1. Introdução ao FixMatch\n",
        "FixMatch é uma técnica que combina pseudo-rotulagem e consistência de dados aumentados. Em resumo, o método:\n",
        "- **Gera pseudo-rótulos** para dados não rotulados, utilizando uma predição confiável de dados fracamente aumentados.\n",
        "- **Aplica uma consistência de pseudo-rótulos**, onde a rede é treinada para produzir as mesmas previsões em versões fortemente aumentadas das mesmas imagens.\n",
        "\n",
        "Para mais informações sobre a arquitetura e a metodologia do FixMatch, vocês podem consultar o [paper original](https://arxiv.org/abs/2001.07685) e/ou ver os slides disponibilizados.\n",
        "\n",
        "### 2. Estrutura da Implementação\n",
        "\n",
        "1. **Dataset e Preparação dos Dados**  \n",
        "   - Use o CIFAR-10 como dataset.\n",
        "   - Prepare duas versões dos dados:\n",
        "     - **Dados rotulados:** Utilizem um subconjunto rotulado do CIFAR-10 com diferentes quantidades de rótulos por classe para experimentação.\n",
        "     - **Dados não rotulados:** O restante do CIFAR-10 deve ser usado como dados não rotulados.\n",
        "\n",
        "2. **Modelo Base**  \n",
        "   - Utilize um modelo de CNN simples ou uma arquitetura pré-definida (sugestão: ResNet-18) para a implementação.\n",
        "\n",
        "3. **Implementação do FixMatch**\n",
        "   - **Pseudo-rotulagem:** Implemente a geração de rótulos para os dados não rotulados usando predições de confiança de uma versão levemente aumentada da imagem.\n",
        "   - **Consistência de Augmentation:** Aplique uma versão fortemente aumentada da imagem e treine a rede para manter consistência nos pseudo-rótulos.\n",
        "   - **Função de Perda**:\n",
        "     - O FixMatch utiliza uma função de perda híbrida, combinando a perda supervisionada e a não supervisionada:\n",
        "       - **Perda Supervisionada:** Aplique a entropia cruzada entre os rótulos reais e as predições do modelo para os dados rotulados.\n",
        "       - **Perda Não Supervisionada (Consistência de Pseudo-rótulos):** Para os dados não rotulados, aplique uma entropia cruzada entre os pseudo-rótulos e as previsões das imagens aumentadas, incluindo apenas as amostras com confiança acima de um limite predefinido (threshold).\n",
        "       - A função de perda final é a soma ponderada das perdas supervisionada e não supervisionada.\n",
        "\n",
        "   - **Detalhes Importantes nas Seções 2.3 e 2.4 do paper**;\n",
        "\n",
        "4. **Treinamento e Otimização**\n",
        "\n",
        "### 3. Experimentos e Análise\n",
        "\n",
        "Para avaliar o desempenho do FixMatch, vocês devem realizar experimentos com diferentes quantidades de dados rotulados. Especificamente, testem com:\n",
        "\n",
        "1. **1 rótulo por classe** (total de 10 rótulos): Este experimento extremo explora o desempenho do FixMatch com uma quantidade mínima de dados rotulados. Observem a eficácia da técnica de pseudo-rotulagem nesse cenário.\n",
        "\n",
        "2. **4 rótulos por classe** (total de 40 rótulos): Com um conjunto pequeno, analisem o desempenho da rede com algumas amostras rotuladas e o impacto dos pseudo-rótulos.\n",
        "\n",
        "3. **25 rótulos por classe** (total de 250 rótulos): Esse experimento permitirá uma análise mais profunda da eficácia do FixMatch em cenários com uma quantidade moderada de rótulos.\n",
        "\n",
        "4. **400 rótulos por classe** (total de 4.000 rótulos): Avaliem o desempenho do modelo com um conjunto mais substancial de dados rotulados, investigando o impacto da quantidade crescente de rótulos.\n",
        "\n",
        "**Proponha pelo menos mais algum teste, fundamente sua escolha e discuta os resultados.**\n",
        "\n",
        "Para cada experimento:\n",
        "   - Treine o modelo e avalie a acurácia nos dados de teste.\n",
        "   - Documente os resultados e compare a eficácia do FixMatch com a quantidade de dados rotulados disponíveis.\n",
        "   - Analise o impacto dos pseudo-rótulos na qualidade do modelo, principalmente nos cenários com poucos rótulos (1, 4 e 25 rótulos por classe).\n",
        "\n",
        "### 4. Apresentação\n",
        "No final, vocês devem preparar e apresentar:\n",
        "\n",
        "1. Slides de apresentação ou relatório:\n",
        "- Explicação da implementação de cada parte do FixMatch. (simples e rápida)\n",
        "- Resultados e gráficos das avaliações para os quatro cenários de rótulos por classe. (Importante)\n",
        "- Análise sobre o impacto da quantidade de dados rotulados, a função de perda híbrida, e o efeito dos thresholds e data augmentation. (Importante)\n",
        "\n",
        "2. Apresentação de 10-15 minutos\n",
        "- Grave uma apresentação do seu slide/relatório cobrindo todos os pontos pedidos.\n",
        "\n",
        "*Note que a apresentação e o conteúdo dos slides deve cobrir todos os requisitos solicitados, pois sua avaliação vai depender 90% da apresentação. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "from collections import defaultdict\n",
        "from os.path import join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LabeledDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, indexes, device = \"cpu\"):\n",
        "        self.dataset = dataset\n",
        "        self.indexes = indexes\n",
        "        self.device = device\n",
        "\n",
        "        self.weak_augmentations = lambda x: x\n",
        "        # self.resize_img = T.Resize(size=img_dim, interpolation=T.InterpolationMode.BILINEAR, antialias=True)\n",
        "        # self.resize_label = T.Resize(size=img_dim, interpolation=T.InterpolationMode.NEAREST)\n",
        "        # self.normalize_img = T.Normalize([105.3549, 107.8312, 109.6686], [5637.0488**0.5, 5869.9844**0.5, 5731.8906**0.5])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Pega o path da imagem e da label e carrega\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.to(torch.float).to(self.device)\n",
        "        image = self.weak_augmentations(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_original_image(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        return decode_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlabeledDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, indexes, device = \"cpu\"):\n",
        "        self.dataset = dataset\n",
        "        self.indexes = indexes\n",
        "        self.device = device\n",
        "        \n",
        "        self.weak_augmentations = lambda x: x\n",
        "        self.strong_augmentations = lambda x: x\n",
        "        # self.resize_img = T.Resize(size=img_dim, interpolation=T.InterpolationMode.BILINEAR, antialias=True)\n",
        "        # self.resize_label = T.Resize(size=img_dim, interpolation=T.InterpolationMode.NEAREST)\n",
        "        # self.normalize_img = T.Normalize([105.3549, 107.8312, 109.6686], [5637.0488**0.5, 5869.9844**0.5, 5731.8906**0.5])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Pega o path da imagem e da label e carrega\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.to(torch.float).to(self.device)\n",
        "        weak_image = self.weak_augmentation(image)\n",
        "        strong_image = self.strong_augmentation(image)\n",
        "        return weak_image, strong_image\n",
        "\n",
        "    def get_original_image(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        return decode_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_split_dataset(dataset, n_classes, n_samples, device = \"cpu\"):\n",
        "    labeled_indexes = []\n",
        "\n",
        "    total_indexes = n_classes * n_samples\n",
        "    frequencies = defaultdict(lambda: 0)\n",
        "    curr = 0\n",
        "\n",
        "    while len(labeled_indexes) < total_indexes:\n",
        "        if curr == len(dataset):\n",
        "            raise RuntimeError(\"Não foi possível fazer split do dataset\")\n",
        "\n",
        "        label = dataset[curr][1]\n",
        "        if frequencies[label] < n_samples:\n",
        "            labeled_indexes.append(curr)\n",
        "            frequencies[label] += 1\n",
        "        curr += 1\n",
        "\n",
        "    unlabeled_indexes = list(set(range(len(dataset))) - set(labeled_indexes))\n",
        "\n",
        "    labeled_dataset = LabeledDataset(dataset, labeled_indexes, device)\n",
        "    unlabeled_dataset = UnlabeledDataset(dataset, unlabeled_indexes, device)\n",
        "    return labeled_dataset, unlabeled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 49950, 50000)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Exemplo:\n",
        "\n",
        "base_dataset = CIFAR10(\"data\", train = True, download = True)\n",
        "labeled_dataset, unlabeled_dataset = get_split_dataset(base_dataset, 10, 5)\n",
        "len(labeled_dataset), len(unlabeled_dataset), len(labeled_dataset) + len(unlabeled_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelResnet18(nn.Module):\n",
        "    def __init__(self, n_classes, device = \"cpu\"):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.resnet = resnet18(weights = ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.resnet.fc = nn.Linear(in_features = 512, out_features = n_classes)\n",
        "        self = self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ModelResnet18(\n",
              "  (resnet): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo = ModelResnet18(10)\n",
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixMatchLoss(nn.Module):\n",
        "    def __init__(self, threshold, weight):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "        self.weight = weight\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, labeled_predictions, labeled_truth, unlabeled_weak_predictions, unlabeled_strong_predictions):\n",
        "        l_s = self.cross_entropy(labeled_predictions, labeled_truth)\n",
        "        \n",
        "        #Pode entrar os logits no erro que o softmax é passado aqui dentro\n",
        "        with torch.no_grad():\n",
        "            unlabeled_weak_predictions = self.softmax(unlabeled_weak_predictions)\n",
        "            mask = unlabeled_weak_predictions.max(dim = 1)[0] > self.threshold\n",
        "        \n",
        "        l_u = self.cross_entropy(unlabeled_strong_predictions[mask], unlabeled_weak_predictions[mask].argmax(dim = 1))\n",
        "        \n",
        "        return l_s + self.weight * l_u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 64\n",
        "mu = 1.5\n",
        "C = 10\n",
        "\n",
        "mock_truth = torch.randint(C, size = (N,))\n",
        "mock_preds = torch.normal(1.0, 5.0, size = (N, C))\n",
        "mock_weak_preds = torch.normal(1.0, 5.0, size = (int(N * mu), C))\n",
        "mock_strong_preds = torch.normal(1.0, 5.0, size = (int(N * mu), C))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = FixMatchLoss(0.7, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14.4168)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss(mock_preds, mock_truth, mock_weak_preds, mock_strong_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Faculdade",
      "language": "python",
      "name": "faculdade"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
