{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xNEJ6JyC6nX"
      },
      "source": [
        "\n",
        "# Implementação e Avaliação do FixMatch com CIFAR-10\n",
        "\n",
        "### Objetivo\n",
        "Neste assignment, vocês implementarão o método FixMatch, uma técnica de aprendizado semi-supervisionado que combina aprendizado supervisionado e não supervisionado. O objetivo é aplicar o FixMatch ao dataset CIFAR-10 para treinar uma rede neural e avaliar os resultados obtidos com diferentes proporções de dados rotulados.\n",
        "\n",
        "### 1. Introdução ao FixMatch\n",
        "FixMatch é uma técnica que combina pseudo-rotulagem e consistência de dados aumentados. Em resumo, o método:\n",
        "- **Gera pseudo-rótulos** para dados não rotulados, utilizando uma predição confiável de dados fracamente aumentados.\n",
        "- **Aplica uma consistência de pseudo-rótulos**, onde a rede é treinada para produzir as mesmas previsões em versões fortemente aumentadas das mesmas imagens.\n",
        "\n",
        "Para mais informações sobre a arquitetura e a metodologia do FixMatch, vocês podem consultar o [paper original](https://arxiv.org/abs/2001.07685) e/ou ver os slides disponibilizados.\n",
        "\n",
        "### 2. Estrutura da Implementação\n",
        "\n",
        "1. **Dataset e Preparação dos Dados**  \n",
        "   - Use o CIFAR-10 como dataset.\n",
        "   - Prepare duas versões dos dados:\n",
        "     - **Dados rotulados:** Utilizem um subconjunto rotulado do CIFAR-10 com diferentes quantidades de rótulos por classe para experimentação.\n",
        "     - **Dados não rotulados:** O restante do CIFAR-10 deve ser usado como dados não rotulados.\n",
        "\n",
        "2. **Modelo Base**  \n",
        "   - Utilize um modelo de CNN simples ou uma arquitetura pré-definida (sugestão: ResNet-18) para a implementação.\n",
        "\n",
        "3. **Implementação do FixMatch**\n",
        "   - **Pseudo-rotulagem:** Implemente a geração de rótulos para os dados não rotulados usando predições de confiança de uma versão levemente aumentada da imagem.\n",
        "   - **Consistência de Augmentation:** Aplique uma versão fortemente aumentada da imagem e treine a rede para manter consistência nos pseudo-rótulos.\n",
        "   - **Função de Perda**:\n",
        "     - O FixMatch utiliza uma função de perda híbrida, combinando a perda supervisionada e a não supervisionada:\n",
        "       - **Perda Supervisionada:** Aplique a entropia cruzada entre os rótulos reais e as predições do modelo para os dados rotulados.\n",
        "       - **Perda Não Supervisionada (Consistência de Pseudo-rótulos):** Para os dados não rotulados, aplique uma entropia cruzada entre os pseudo-rótulos e as previsões das imagens aumentadas, incluindo apenas as amostras com confiança acima de um limite predefinido (threshold).\n",
        "       - A função de perda final é a soma ponderada das perdas supervisionada e não supervisionada.\n",
        "\n",
        "   - **Detalhes Importantes nas Seções 2.3 e 2.4 do paper**;\n",
        "\n",
        "4. **Treinamento e Otimização**\n",
        "\n",
        "### 3. Experimentos e Análise\n",
        "\n",
        "Para avaliar o desempenho do FixMatch, vocês devem realizar experimentos com diferentes quantidades de dados rotulados. Especificamente, testem com:\n",
        "\n",
        "1. **1 rótulo por classe** (total de 10 rótulos): Este experimento extremo explora o desempenho do FixMatch com uma quantidade mínima de dados rotulados. Observem a eficácia da técnica de pseudo-rotulagem nesse cenário.\n",
        "\n",
        "2. **4 rótulos por classe** (total de 40 rótulos): Com um conjunto pequeno, analisem o desempenho da rede com algumas amostras rotuladas e o impacto dos pseudo-rótulos.\n",
        "\n",
        "3. **25 rótulos por classe** (total de 250 rótulos): Esse experimento permitirá uma análise mais profunda da eficácia do FixMatch em cenários com uma quantidade moderada de rótulos.\n",
        "\n",
        "4. **400 rótulos por classe** (total de 4.000 rótulos): Avaliem o desempenho do modelo com um conjunto mais substancial de dados rotulados, investigando o impacto da quantidade crescente de rótulos.\n",
        "\n",
        "**Proponha pelo menos mais algum teste, fundamente sua escolha e discuta os resultados.**\n",
        "\n",
        "Para cada experimento:\n",
        "   - Treine o modelo e avalie a acurácia nos dados de teste.\n",
        "   - Documente os resultados e compare a eficácia do FixMatch com a quantidade de dados rotulados disponíveis.\n",
        "   - Analise o impacto dos pseudo-rótulos na qualidade do modelo, principalmente nos cenários com poucos rótulos (1, 4 e 25 rótulos por classe).\n",
        "\n",
        "### 4. Apresentação\n",
        "No final, vocês devem preparar e apresentar:\n",
        "\n",
        "1. Slides de apresentação ou relatório:\n",
        "- Explicação da implementação de cada parte do FixMatch. (simples e rápida)\n",
        "- Resultados e gráficos das avaliações para os quatro cenários de rótulos por classe. (Importante)\n",
        "- Análise sobre o impacto da quantidade de dados rotulados, a função de perda híbrida, e o efeito dos thresholds e data augmentation. (Importante)\n",
        "\n",
        "2. Apresentação de 10-15 minutos\n",
        "- Grave uma apresentação do seu slide/relatório cobrindo todos os pontos pedidos.\n",
        "\n",
        "*Note que a apresentação e o conteúdo dos slides deve cobrir todos os requisitos solicitados, pois sua avaliação vai depender 90% da apresentação. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision.io import decode_image\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import defaultdict\n",
        "from os.path import join\n",
        "from itertools import cycle\n",
        "\n",
        "from ctaugment import CTAugment\n",
        "\n",
        "DEVICE = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LabeledDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, indexes, device = \"cpu\"):\n",
        "        self.dataset = dataset\n",
        "        self.indexes = indexes\n",
        "        self.device = device\n",
        "\n",
        "        self.weak_augmentations = v2.Compose([\n",
        "            v2.RandomHorizontalFlip(p=0.5),\n",
        "            v2.RandomAffine(degrees=0, translate=(0.125, 0.125)), # translação em até 12,5% na vertical e horizontal\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Pega o path da imagem e da label e carrega\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.to(torch.float).to(self.device)\n",
        "        image = self.weak_augmentations(image) # Se acharmos útil podemos condicionar o augmentation ao treino e/ou à alguma probabilidade\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_original_image(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        return decode_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlabeledDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, indexes, device = \"cpu\", ctaugment = True):\n",
        "        self.dataset = dataset\n",
        "        self.indexes = indexes\n",
        "        self.device = device\n",
        "        \n",
        "        self.weak_augmentations = v2.Compose([\n",
        "            v2.RandomHorizontalFlip(p=0.5),\n",
        "            v2.RandomAffine(degrees=0, translate=(0.125, 0.125)), # translação em até 12,5% na vertical e horizontal\n",
        "        ])\n",
        "\n",
        "        self.strong_augmentations = v2.Compose([\n",
        "                CTAugment() if ctaugment else v2.RandAugment(),\n",
        "                v2.RandomErasing(p=1, \n",
        "                                ratio=(1, 1), \n",
        "                                scale=(0.01, 0.01), \n",
        "                                value=127),\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Pega o path da imagem e da label e carrega\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.to(torch.float).to(self.device)\n",
        "        weak_image = self.weak_augmentations(image) # Mesma possiblididade de condicionar aqui também\n",
        "        strong_image = self.strong_augmentations(image)\n",
        "        return weak_image, strong_image\n",
        "\n",
        "    def get_original_image(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        return decode_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_split_dataset(dataset, n_classes, n_samples, device = \"cpu\"):\n",
        "    labeled_indexes = []\n",
        "\n",
        "    total_indexes = n_classes * n_samples\n",
        "    frequencies = defaultdict(lambda: 0)\n",
        "    curr = 0\n",
        "\n",
        "    while len(labeled_indexes) < total_indexes:\n",
        "        if curr == len(dataset):\n",
        "            raise RuntimeError(\"Não foi possível fazer split do dataset\")\n",
        "\n",
        "        label = dataset[curr][1]\n",
        "        if frequencies[label] < n_samples:\n",
        "            labeled_indexes.append(curr)\n",
        "            frequencies[label] += 1\n",
        "        curr += 1\n",
        "\n",
        "    unlabeled_indexes = list(set(range(len(dataset))) - set(labeled_indexes))\n",
        "\n",
        "    labeled_dataset = LabeledDataset(dataset, labeled_indexes, device)\n",
        "    unlabeled_dataset = UnlabeledDataset(dataset, unlabeled_indexes, device)\n",
        "    return labeled_dataset, unlabeled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 49950, 50000)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Exemplo:\n",
        "\n",
        "base_dataset = CIFAR10(\"data\", train = True, download = True)\n",
        "labeled_dataset, unlabeled_dataset = get_split_dataset(base_dataset, 10, 5)\n",
        "len(labeled_dataset), len(unlabeled_dataset), len(labeled_dataset) + len(unlabeled_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelResnet18(nn.Module):\n",
        "    def __init__(self, n_classes, device = \"cpu\"):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.resnet = resnet18(weights = ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.resnet.fc = nn.Linear(in_features = 512, out_features = n_classes)\n",
        "        self = self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ModelResnet18(\n",
              "  (resnet): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo = ModelResnet18(10)\n",
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixMatchLoss(nn.Module):\n",
        "    def __init__(self, threshold, weight):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "        self.weight = weight\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, labeled_predictions, labeled_truth, unlabeled_weak_predictions, unlabeled_strong_predictions):\n",
        "        l_s = self.cross_entropy(labeled_predictions, labeled_truth)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            unlabeled_weak_predictions = self.softmax(unlabeled_weak_predictions)\n",
        "            mask = unlabeled_weak_predictions.max(dim = 1)[0] > self.threshold\n",
        "            if sum(mask) == 0:\n",
        "                return l_s\n",
        "\n",
        "        l_u = self.cross_entropy(unlabeled_strong_predictions[mask], unlabeled_weak_predictions[mask].argmax(dim = 1))\n",
        "\n",
        "        return l_s + self.weight * l_u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(16.8428)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 64\n",
        "mu = 1.5\n",
        "C = 10\n",
        "\n",
        "mock_truth = torch.randint(C, size = (N,))\n",
        "mock_preds = torch.normal(1.0, 5.0, size = (N, C))\n",
        "mock_weak_preds = torch.normal(1.0, 5.0, size = (int(N * mu), C))\n",
        "mock_strong_preds = torch.normal(1.0, 5.0, size = (int(N * mu), C))\n",
        "\n",
        "loss = FixMatchLoss(0.7, 1)\n",
        "loss(mock_preds, mock_truth, mock_weak_preds, mock_strong_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, labeled_dataset, unlabeled_dataset, criterion, optimizer, val_dataset = None, device = \"cpu\"):\n",
        "        self._model = model.to(device)\n",
        "\n",
        "        self._labeled_dataset = labeled_dataset\n",
        "        self._unlabeled_dataset = unlabeled_dataset\n",
        "        self._val_dataset = val_dataset\n",
        "\n",
        "        self._criterion = criterion\n",
        "        self._optimizer = optimizer\n",
        "        self._device = device\n",
        "        print(device)\n",
        "\n",
        "        self._history = {\n",
        "            \"train_loss\": [],\n",
        "            \"val_acc\": []\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def history(self):\n",
        "        return self._history\n",
        "    \n",
        "    def train_one_epoch(self, epoch):\n",
        "        self._model.train()\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        zip_loaders = zip(cycle(self._labeled_dataloader), self._unlabeled_dataloader)\n",
        "        progress_bar = tqdm(zip_loaders, desc = f\"Epoch {epoch + 1} | Training\", total = len(self._unlabeled_dataloader))\n",
        "\n",
        "        for i, (labeled_data, unlabeled_data) in enumerate(progress_bar):\n",
        "            # labeled_data = next(self._labeled_dataloader)\n",
        "            # print(i, labeled_data[1].shape, labeled_data[1])\n",
        "\n",
        "            labeled_images, labeled_labels = labeled_data\n",
        "            labeled_images = labeled_images.to(self._device)\n",
        "            labeled_labels = labeled_labels.to(self._device)\n",
        "\n",
        "            unlabeled_weak, unlabeled_strong = unlabeled_data\n",
        "            unlabeled_weak = unlabeled_weak.to(self._device)\n",
        "            unlabeled_strong = unlabeled_strong.to(self._device)\n",
        "\n",
        "            self._optimizer.zero_grad()\n",
        "\n",
        "            labeled_predictions = self._model(labeled_images)\n",
        "            unlabeled_weak_predictions = self._model(unlabeled_weak)\n",
        "            unlabeled_strong_predictions = self._model(unlabeled_strong)\n",
        "\n",
        "            loss = self._criterion(\n",
        "                labeled_predictions,\n",
        "                labeled_labels,\n",
        "                unlabeled_weak_predictions,\n",
        "                unlabeled_strong_predictions,\n",
        "            )\n",
        "            loss.backward()\n",
        "            self._optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss = loss.item())\n",
        "\n",
        "        epoch_loss = running_loss / len(self._unlabeled_dataloader)\n",
        "        return epoch_loss\n",
        "\n",
        "    def evaluate_accuracy(self, dataloader):\n",
        "        self._model.eval()\n",
        "        \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for images, labels in dataloader:\n",
        "                images = images.to(torch.float).to(self._device)\n",
        "                labels = labels.to(self._device)\n",
        "                \n",
        "                outputs = self._model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1) \n",
        "                \n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        accuracy = 100 * correct / total\n",
        "        return accuracy\n",
        "\n",
        "    def fit(self, epochs, batch_size, mu=7):\n",
        "        self._labeled_dataloader = DataLoader(self._labeled_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self._unlabeled_dataloader = DataLoader(self._unlabeled_dataset, batch_size = int(batch_size * mu), shuffle=True)\n",
        "        if self._val_dataset:\n",
        "            self._val_dataloader = DataLoader(self._val_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss = self.train_one_epoch(epoch)\n",
        "            self._history[\"train_loss\"].append(train_loss)\n",
        "            \n",
        "            if self._val_dataset:\n",
        "                val_acc = self.evaluate_accuracy(self._val_dataloader)\n",
        "                self.history[\"val_acc\"].append(val_acc)\n",
        "                print(f\"val acc {val_acc}\")\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}: mean batch loss {train_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = 10\n",
        "n_samples = 10\n",
        "epochs = 10\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "threshold = 0.9\n",
        "lambda_u = 1.0\n",
        "\n",
        "base_dataset = CIFAR10(\"data\", train=True, download=True, transform=v2.ToImage())\n",
        "test_dataset = CIFAR10(\"data\", train=False, download=True, transform=v2.ToImage())\n",
        "labeled_dataset, unlabeled_dataset = get_split_dataset(base_dataset, n_classes, n_samples, DEVICE)\n",
        "\n",
        "model = ModelResnet18(n_classes, DEVICE)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "loss_function = FixMatchLoss(threshold, lambda_u)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    labeled_dataset,\n",
        "    unlabeled_dataset,\n",
        "    loss_function,\n",
        "    optimizer,\n",
        "    val_dataset=test_dataset,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "trainer.fit(epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Faculdade",
      "language": "python",
      "name": "faculdade"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
