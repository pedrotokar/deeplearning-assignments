{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xNEJ6JyC6nX"
      },
      "source": [
        "\n",
        "# Implementação e Avaliação do FixMatch com CIFAR-10\n",
        "\n",
        "### Objetivo\n",
        "Neste assignment, vocês implementarão o método FixMatch, uma técnica de aprendizado semi-supervisionado que combina aprendizado supervisionado e não supervisionado. O objetivo é aplicar o FixMatch ao dataset CIFAR-10 para treinar uma rede neural e avaliar os resultados obtidos com diferentes proporções de dados rotulados.\n",
        "\n",
        "### 1. Introdução ao FixMatch\n",
        "FixMatch é uma técnica que combina pseudo-rotulagem e consistência de dados aumentados. Em resumo, o método:\n",
        "- **Gera pseudo-rótulos** para dados não rotulados, utilizando uma predição confiável de dados fracamente aumentados.\n",
        "- **Aplica uma consistência de pseudo-rótulos**, onde a rede é treinada para produzir as mesmas previsões em versões fortemente aumentadas das mesmas imagens.\n",
        "\n",
        "Para mais informações sobre a arquitetura e a metodologia do FixMatch, vocês podem consultar o [paper original](https://arxiv.org/abs/2001.07685) e/ou ver os slides disponibilizados.\n",
        "\n",
        "### 2. Estrutura da Implementação\n",
        "\n",
        "1. **Dataset e Preparação dos Dados**  \n",
        "   - Use o CIFAR-10 como dataset.\n",
        "   - Prepare duas versões dos dados:\n",
        "     - **Dados rotulados:** Utilizem um subconjunto rotulado do CIFAR-10 com diferentes quantidades de rótulos por classe para experimentação.\n",
        "     - **Dados não rotulados:** O restante do CIFAR-10 deve ser usado como dados não rotulados.\n",
        "\n",
        "2. **Modelo Base**  \n",
        "   - Utilize um modelo de CNN simples ou uma arquitetura pré-definida (sugestão: ResNet-18) para a implementação.\n",
        "\n",
        "3. **Implementação do FixMatch**\n",
        "   - **Pseudo-rotulagem:** Implemente a geração de rótulos para os dados não rotulados usando predições de confiança de uma versão levemente aumentada da imagem.\n",
        "   - **Consistência de Augmentation:** Aplique uma versão fortemente aumentada da imagem e treine a rede para manter consistência nos pseudo-rótulos.\n",
        "   - **Função de Perda**:\n",
        "     - O FixMatch utiliza uma função de perda híbrida, combinando a perda supervisionada e a não supervisionada:\n",
        "       - **Perda Supervisionada:** Aplique a entropia cruzada entre os rótulos reais e as predições do modelo para os dados rotulados.\n",
        "       - **Perda Não Supervisionada (Consistência de Pseudo-rótulos):** Para os dados não rotulados, aplique uma entropia cruzada entre os pseudo-rótulos e as previsões das imagens aumentadas, incluindo apenas as amostras com confiança acima de um limite predefinido (threshold).\n",
        "       - A função de perda final é a soma ponderada das perdas supervisionada e não supervisionada.\n",
        "\n",
        "   - **Detalhes Importantes nas Seções 2.3 e 2.4 do paper**;\n",
        "\n",
        "4. **Treinamento e Otimização**\n",
        "\n",
        "### 3. Experimentos e Análise\n",
        "\n",
        "Para avaliar o desempenho do FixMatch, vocês devem realizar experimentos com diferentes quantidades de dados rotulados. Especificamente, testem com:\n",
        "\n",
        "1. **1 rótulo por classe** (total de 10 rótulos): Este experimento extremo explora o desempenho do FixMatch com uma quantidade mínima de dados rotulados. Observem a eficácia da técnica de pseudo-rotulagem nesse cenário.\n",
        "\n",
        "2. **4 rótulos por classe** (total de 40 rótulos): Com um conjunto pequeno, analisem o desempenho da rede com algumas amostras rotuladas e o impacto dos pseudo-rótulos.\n",
        "\n",
        "3. **25 rótulos por classe** (total de 250 rótulos): Esse experimento permitirá uma análise mais profunda da eficácia do FixMatch em cenários com uma quantidade moderada de rótulos.\n",
        "\n",
        "4. **400 rótulos por classe** (total de 4.000 rótulos): Avaliem o desempenho do modelo com um conjunto mais substancial de dados rotulados, investigando o impacto da quantidade crescente de rótulos.\n",
        "\n",
        "**Proponha pelo menos mais algum teste, fundamente sua escolha e discuta os resultados.**\n",
        "\n",
        "Para cada experimento:\n",
        "   - Treine o modelo e avalie a acurácia nos dados de teste.\n",
        "   - Documente os resultados e compare a eficácia do FixMatch com a quantidade de dados rotulados disponíveis.\n",
        "   - Analise o impacto dos pseudo-rótulos na qualidade do modelo, principalmente nos cenários com poucos rótulos (1, 4 e 25 rótulos por classe).\n",
        "\n",
        "### 4. Apresentação\n",
        "No final, vocês devem preparar e apresentar:\n",
        "\n",
        "1. Slides de apresentação ou relatório:\n",
        "- Explicação da implementação de cada parte do FixMatch. (simples e rápida)\n",
        "- Resultados e gráficos das avaliações para os quatro cenários de rótulos por classe. (Importante)\n",
        "- Análise sobre o impacto da quantidade de dados rotulados, a função de perda híbrida, e o efeito dos thresholds e data augmentation. (Importante)\n",
        "\n",
        "2. Apresentação de 10-15 minutos\n",
        "- Grave uma apresentação do seu slide/relatório cobrindo todos os pontos pedidos.\n",
        "\n",
        "*Note que a apresentação e o conteúdo dos slides deve cobrir todos os requisitos solicitados, pois sua avaliação vai depender 90% da apresentação. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim import Adam, SGD\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision.io import decode_image\n",
        "from ctaugment import CTAugment\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import defaultdict\n",
        "from os.path import join\n",
        "from itertools import cycle\n",
        "import json\n",
        "\n",
        "\n",
        "DEVICE = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LabeledDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, indexes, device = \"cpu\"):\n",
        "        self.dataset = dataset\n",
        "        self.indexes = indexes\n",
        "        self.device = device\n",
        "\n",
        "        self.weak_augmentations = v2.Compose([\n",
        "            v2.RandomHorizontalFlip(p=0.5),\n",
        "            v2.RandomAffine(degrees=0, translate=(0.125, 0.125)), # translação em até 12,5% na vertical e horizontal\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Pega o path da imagem e da label e carrega\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.to(torch.float).to(self.device)\n",
        "        image = self.weak_augmentations(image) # Se acharmos útil podemos condicionar o augmentation ao treino e/ou à alguma probabilidade\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_original_image(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        return decode_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlabeledDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, indexes, device = \"cpu\", ctaugment = True):\n",
        "        self.dataset = dataset\n",
        "        self.indexes = indexes\n",
        "        self.device = device\n",
        "        \n",
        "        self.weak_augmentations = v2.Compose([\n",
        "            v2.RandomHorizontalFlip(p=0.5),\n",
        "            v2.RandomAffine(degrees=0, translate=(0.125, 0.125)), # translação em até 12,5% na vertical e horizontal\n",
        "        ])\n",
        "\n",
        "        self.strong_augmentations = v2.Compose([\n",
        "                CTAugment() if ctaugment else v2.RandAugment(),\n",
        "                v2.RandomErasing(p=1, \n",
        "                                ratio=(1, 1), \n",
        "                                scale=(0.01, 0.01), \n",
        "                                value=127),\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Pega o path da imagem e da label e carrega\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.to(torch.float).to(self.device)\n",
        "        weak_image = self.weak_augmentations(image) # Mesma possiblididade de condicionar aqui também\n",
        "        strong_image = self.strong_augmentations(image)\n",
        "        return weak_image, strong_image\n",
        "\n",
        "    def get_original_image(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        return decode_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_split_dataset(dataset, n_classes, n_samples, device = \"cpu\"):\n",
        "    labeled_indexes = []\n",
        "\n",
        "    total_indexes = n_classes * n_samples\n",
        "    frequencies = defaultdict(lambda: 0)\n",
        "    curr = 0\n",
        "\n",
        "    while len(labeled_indexes) < total_indexes:\n",
        "        if curr == len(dataset):\n",
        "            raise RuntimeError(\"Não foi possível fazer split do dataset\")\n",
        "\n",
        "        label = dataset[curr][1]\n",
        "        if frequencies[label] < n_samples:\n",
        "            labeled_indexes.append(curr)\n",
        "            frequencies[label] += 1\n",
        "        curr += 1\n",
        "\n",
        "    unlabeled_indexes = list(set(range(len(dataset))) - set(labeled_indexes))\n",
        "\n",
        "    labeled_dataset = LabeledDataset(dataset, labeled_indexes, device)\n",
        "    unlabeled_dataset = UnlabeledDataset(dataset, unlabeled_indexes, device)\n",
        "    return labeled_dataset, unlabeled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 49950, 50000)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Exemplo:\n",
        "\n",
        "base_dataset = CIFAR10(\"data\", train = True, download = True)\n",
        "labeled_dataset, unlabeled_dataset = get_split_dataset(base_dataset, 10, 5)\n",
        "len(labeled_dataset), len(unlabeled_dataset), len(labeled_dataset) + len(unlabeled_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelResnet18(nn.Module):\n",
        "    def __init__(self, n_classes, device = \"cpu\"):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.resnet = resnet18(weights = ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.resnet.fc = nn.Linear(in_features = 512, out_features = n_classes)\n",
        "        self = self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ModelResnet18(\n",
              "  (resnet): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo = ModelResnet18(10)\n",
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixMatchLoss(nn.Module):\n",
        "    def __init__(self, threshold, weight):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "        self.weight = weight\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, labeled_predictions, labeled_truth, unlabeled_weak_predictions, unlabeled_strong_predictions):\n",
        "        l_s = self.cross_entropy(labeled_predictions, labeled_truth)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            unlabeled_weak_predictions = self.softmax(unlabeled_weak_predictions)\n",
        "            mask = unlabeled_weak_predictions.max(dim = 1)[0] > self.threshold\n",
        "            if sum(mask) == 0:\n",
        "                return l_s\n",
        "\n",
        "        l_u = self.cross_entropy(unlabeled_strong_predictions[mask], unlabeled_weak_predictions[mask].argmax(dim = 1))\n",
        "\n",
        "        return l_s + self.weight * l_u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(16.8428)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 64\n",
        "mu = 1.5\n",
        "C = 10\n",
        "\n",
        "mock_truth = torch.randint(C, size = (N,))\n",
        "mock_preds = torch.normal(1.0, 5.0, size = (N, C))\n",
        "mock_weak_preds = torch.normal(1.0, 5.0, size = (int(N * mu), C))\n",
        "mock_strong_preds = torch.normal(1.0, 5.0, size = (int(N * mu), C))\n",
        "\n",
        "loss = FixMatchLoss(0.7, 1)\n",
        "loss(mock_preds, mock_truth, mock_weak_preds, mock_strong_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, labeled_dataset, unlabeled_dataset, criterion, optimizer, val_dataset = None, device = \"cpu\"):\n",
        "        self._model = model.to(device)\n",
        "\n",
        "        self._labeled_dataset = labeled_dataset\n",
        "        self._unlabeled_dataset = unlabeled_dataset\n",
        "        self._val_dataset = val_dataset\n",
        "\n",
        "        self._criterion = criterion\n",
        "        self._optimizer = optimizer\n",
        "        self._device = device\n",
        "        print(device)\n",
        "\n",
        "        self._history = {\n",
        "            \"train_loss\": [],\n",
        "            \"val_acc\": []\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def history(self):\n",
        "        return self._history\n",
        "    \n",
        "    def train_one_epoch(self, epoch):\n",
        "        self._model.train()\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        zip_loaders = zip(cycle(self._labeled_dataloader), self._unlabeled_dataloader)\n",
        "        progress_bar = tqdm(zip_loaders, desc = f\"Epoch {epoch + 1} | Training\", total = len(self._unlabeled_dataloader))\n",
        "\n",
        "        for i, (labeled_data, unlabeled_data) in enumerate(progress_bar):\n",
        "            # labeled_data = next(self._labeled_dataloader)\n",
        "            # print(i, labeled_data[1].shape, labeled_data[1])\n",
        "\n",
        "            labeled_images, labeled_labels = labeled_data\n",
        "            labeled_images = labeled_images.to(self._device)\n",
        "            labeled_labels = labeled_labels.to(self._device)\n",
        "\n",
        "            unlabeled_weak, unlabeled_strong = unlabeled_data\n",
        "            unlabeled_weak = unlabeled_weak.to(self._device)\n",
        "            unlabeled_strong = unlabeled_strong.to(self._device)\n",
        "\n",
        "            self._optimizer.zero_grad()\n",
        "\n",
        "            labeled_predictions = self._model(labeled_images)\n",
        "            unlabeled_weak_predictions = self._model(unlabeled_weak)\n",
        "            unlabeled_strong_predictions = self._model(unlabeled_strong)\n",
        "\n",
        "            loss = self._criterion(\n",
        "                labeled_predictions,\n",
        "                labeled_labels,\n",
        "                unlabeled_weak_predictions,\n",
        "                unlabeled_strong_predictions,\n",
        "            )\n",
        "            loss.backward()\n",
        "            self._optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss = loss.item())\n",
        "\n",
        "        epoch_loss = running_loss / len(self._unlabeled_dataloader)\n",
        "        return epoch_loss\n",
        "\n",
        "    def evaluate_accuracy(self, dataloader):\n",
        "        self._model.eval()\n",
        "        \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for images, labels in dataloader:\n",
        "                images = images.to(torch.float).to(self._device)\n",
        "                labels = labels.to(self._device)\n",
        "                \n",
        "                outputs = self._model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1) \n",
        "                \n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        accuracy = 100 * correct / total\n",
        "        return accuracy\n",
        "\n",
        "    def fit(self, epochs, batch_size, mu = 7, num_workers = 0):\n",
        "        self._labeled_dataloader = DataLoader(self._labeled_dataset, batch_size=batch_size, shuffle=True, num_workers = num_workers)\n",
        "        self._unlabeled_dataloader = DataLoader(self._unlabeled_dataset, batch_size = int(batch_size * mu), shuffle=True, num_workers = num_workers)\n",
        "        if self._val_dataset:\n",
        "            self._val_dataloader = DataLoader(self._val_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss = self.train_one_epoch(epoch)\n",
        "            self._history[\"train_loss\"].append(train_loss)\n",
        "            \n",
        "            if self._val_dataset:\n",
        "                val_acc = self.evaluate_accuracy(self._val_dataloader)\n",
        "                self.history[\"val_acc\"].append(val_acc)\n",
        "                print(f\"Epoch {epoch + 1}: mean batch loss {train_loss} | val acc {val_acc}%\")\n",
        "            else:\n",
        "                print(f\"Epoch {epoch + 1}: mean batch loss {train_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = 10\n",
        "n_samples = 400\n",
        "epochs = 50\n",
        "\n",
        "batch_size = 64\n",
        "learning_rate = 0.03\n",
        "threshold = 0.9\n",
        "lambda_u = 1.0\n",
        "\n",
        "base_dataset = CIFAR10(\"data\", train=True, download=True, transform=v2.ToImage())\n",
        "test_dataset = CIFAR10(\"data\", train=False, download=True, transform=v2.ToImage())\n",
        "labeled_dataset, unlabeled_dataset = get_split_dataset(base_dataset, n_classes, n_samples)\n",
        "\n",
        "model = ModelResnet18(n_classes, DEVICE)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = SGD(model.parameters(), lr = learning_rate, momentum = 0.9, nesterov = True)\n",
        "loss_function = FixMatchLoss(threshold, lambda_u)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    labeled_dataset,\n",
        "    unlabeled_dataset,\n",
        "    loss_function,\n",
        "    optimizer,\n",
        "    val_dataset=test_dataset,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "trainer.fit(epochs, batch_size, num_workers = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f99162ecb30>]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(trainer._history[\"train_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"modelo_prototipo.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"modelo_prototipo.json\", \"w\") as f:\n",
        "    json.dump(trainer._history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Faculdade",
      "language": "python",
      "name": "faculdade"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
